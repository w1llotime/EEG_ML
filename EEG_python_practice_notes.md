# EEG ML Practice Model
This is a basic EEG signal generation + machine learning model, only for learning purposes. This signal is not a real signal, rather generated using the superposition of sine waves. 
Most of the code is from gemini and I've only tried to replicate it. The matplotlib part is entirely copied from gemini.

After running it you can see the following nice diagram.

<img width="400" alt="Screenshot 2025-07-09 at 4 15 38â€¯PM" src="https://github.com/user-attachments/assets/82e5b07f-1274-4159-adc6-eedb67e2ea38" />

I made this for the purpose of just trying to create an EEG ML model, a really bad and imperfect. I just wanted to get one out, to familiarize myself with how one works. Inside this file I will be discussing how each step works and what I learned. I obviously haven't fully understood it, but I'm glad I made this rough model which I built an understanding and can later implement it fully on my own and improve on it.

# Steps
## Step 1 - EEG signal generation
1. We need to generate a EEG signal using sine waves. First we define the time range where the signal is recorded. It involves a starting point, endpoint, and the amount of timestamps within the signal.
2. We need to define dominant frequencies, e.g. [6Hz, 8Hz, 15Hz] for our signal classes. We treat each frequency like a constant in the sine function, in which time is an input that is varied along the range defined in the first step. And thus we get a different sine wave for each frequency.
3. Lastly we superimpose the waves on each other to get a mixed signal.


```python
import numpy as np
from scipy.signal import welch # More robust for power spectral density
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt


def generate_eeg (total_duration, dominant_freq, sfreq, noise = 0.5):
    time = np.linspace(0, total_duration, int(total_duration * sfreq))
    signal = np.zeros_like(time) 
    for freq in (dominant_freq):
        signal += np.sin(2 * np.pi * time * freq) 
    signal += np.random.randn(len(time))
    return signal

total_duration = 2 # 100 seconds
s_freq = 250 # 10 s-1
dominant_freq_class0 = [5,8,10]
dominant_freq_class1 = [15,20,30]
signal0 = generate_eeg (total_duration, dominant_freq_class0, s_freq, noise = 0.5)
signal1 = generate_eeg (total_duration, dominant_freq_class0, s_freq, noise = 0.5)
n_epochs_per_class = 200 # Number of simulated trials for each class

eeg_data = []
labels = []

for _ in range (n_epochs_per_class):
    eeg_data.append(signal0)
    labels.append(0)

for _ in range (n_epochs_per_class):
    eeg_data.append(signal1)
    labels.append(1)

eeg_data = np.array(eeg_data)
labels =np.array(labels)

print (eeg_data.shape) #This should give 200 epochs (rows) times columns
print (labels.shape)

def extract_features (total_epochs, sfreq): #sfreq is always sampling frequency
    features =[]
    
    bands = {"delta": (0.5, 4),
        "theta": (4, 8),
        "alpha": (8, 13),
        "beta": (13, 30),}
    for i, epoch in enumerate (total_epochs):
        nperseg = min(sfreq * 2, len(epoch))
        if nperseg == 0: # Handle very short epochs if they occur
            print(f"Warning: Epoch {i} is too short to compute PSD. Skipping.")
            features.append(np.zeros(len(bands))) # Append zeros if epoch too short
            continue
        
        band_powers = []   
        freqs, psd = welch(epoch, sfreq, nperseg=nperseg, noverlap=nperseg // 2) # this line needs to be in the loop. For we need to do frequencies and psd for each epoch.

        for band_name, (low, high) in bands.items():
            index = np.logical_and(low <= freqs, freqs <= high)
            # now let's integrate to find the power contained in each band"
            power = np.trapezoid(psd[index], freqs[index]) # basically by having the psd of that correct frequency index and the frequency.
            band_powers.append(power)
        features.append(band_powers) #by the end, we have a list of powers! Each row is an epoch. And the values in each row represent the amount of power each frequency contributes. This is because we are running thorugh each of the frequencies. 

    return np.array(features)
    
# for each epoch,(running through all the frecuencies in it, and then for all )

# done. feature extraction. Now we have to separate the model into training data and testing data.

X= extract_features(eeg_data, s_freq)
y= labels
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
# test_size=0.3:
# This parameter tells train_test_split to allocate 30% of the total data to the testing set and the remaining 70% to the training set.
# For the testing set: 0.3 * 400 = 120 samples (epochs)
# For the training set: 0.7 * 400 = 280 samples (epochs)

print(f"Training features shape: {x_train.shape}")
print(f"Testing features shape: {x_test.shape}")
print(f"Training labels shape: {y_train.shape}")
print(f"Testing labels shape: {y_test.shape}")

# --- 4. Build and Train a Classification Model ---
# We'll use Logistic Regression, a simple yet effective linear model.

model = LogisticRegression(max_iter=1000) # Increase max_iter for convergence
model.fit(x_train, y_train)


# --- 5. Evaluate the Model ---

y_pred = model.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred, target_names=["Relaxed (0)", "Active (1)"])

print(f"\nModel Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(report)

# For now, I am just going to copy the matplotlib stuff from gemini cause I don't know how to code it rn.

print(f"Training features shape: {x_train.shape}")
print(f"Testing features shape: {x_test.shape}")
print(f"Training labels shape: {y_train.shape}")
print(f"Testing labels shape: {y_test.shape}")

# --- 4. Build and Train a Classification Model ---
# We'll use Logistic Regression, a simple yet effective linear model.

print("Training Logistic Regression model...")
model = LogisticRegression(max_iter=1000) # Increase max_iter for convergence
model.fit(x_train, y_train)
print("Model training complete.")

# --- 5. Evaluate the Model ---
print("Evaluating model performance...")
y_pred = model.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred, target_names=["Relaxed (0)", "Active (1)"])

print(f"\nModel Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(report)

# --- 6. Visualization (Optional) ---
# Plot an example of raw signal and its PSD for each class

plt.figure(figsize=(14, 8))

# Plot raw signal examples
plt.subplot(2, 2, 1)
plt.plot(np.linspace(0, total_duration, eeg_data.shape[1], endpoint=False), eeg_data[0])
plt.title('Example Raw EEG Signal - Class 0 (Relaxed)')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.grid(True)

plt.subplot(2, 2, 2)
plt.plot(np.linspace(0, total_duration, eeg_data.shape[1], endpoint=False), eeg_data[n_epochs_per_class])
plt.title('Example Raw EEG Signal - Class 1 (Active)')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.grid(True)

# Plot PSD examples
# Re-calculate PSD for plotting (already done for features, but good to visualize)
freqs0, psd0 = welch(eeg_data[0], s_freq, nperseg=min(s_freq * 2, eeg_data.shape[1]), noverlap=min(s_freq * 2, eeg_data.shape[1]) // 2)
freqs1, psd1 = welch(eeg_data[n_epochs_per_class], s_freq, nperseg=min(s_freq * 2, eeg_data.shape[1]), noverlap=min(s_freq * 2, eeg_data.shape[1]) // 2)

plt.subplot(2, 2, 3)
plt.semilogy(freqs0, psd0)
plt.title('PSD for Class 0 (Relaxed)')
plt.xlabel('Frequency (Hz)')
plt.ylabel('PSD (V^2/Hz)')
plt.xlim(0, 50) # Limit x-axis for better visualization of main bands
plt.grid(True)

plt.subplot(2, 2, 4)
plt.semilogy(freqs1, psd1)
plt.title('PSD for Class 1 (Active)')
plt.xlabel('Frequency (Hz)')
plt.ylabel('PSD (V^2/Hz)')
plt.xlim(0, 50) # Limit x-axis for better visualization of main bands
plt.grid(True)

plt.tight_layout()
plt.show()

print("\n--- Model Coefficients (Feature Importance) ---")
# The coefficients of the Logistic Regression model can give insight into
# which frequency bands were most important for classification.
# The order of coefficients corresponds to the order of bands:
# [delta, theta, alpha, beta, gamma]
band_names = ["delta", "theta", "alpha", "beta"]
for i, coef in enumerate(model.coef_[0]):
    print(f"{band_names[i]}: {coef:.4f}")

# Interpretation: A positive coefficient means that higher power in that band
# is associated with the positive class (Class 1 - "Active" in our case).
# A negative coefficient means higher power is associated with the negative
# class (Class 0 - "Relaxed").

```



